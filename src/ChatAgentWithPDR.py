"""
èŠå¤©Agentã€æ”¯æŒå·¥å…·è°ƒç”¨ã€å†å²è·Ÿè¸ªã€RAGã€è®°å¿†ç¼“å­˜
"""

import os
import sys
import asyncio
from typing import List, Any
# LangChain ç›¸å…³å¯¼å…¥
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables import ConfigurableFieldSpec
from langchain_core.tools import StructuredTool, ToolException
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.chat_message_histories import RedisChatMessageHistory
from pydantic import BaseModel, Field
from langchain_core.messages import trim_messages
from langchain_core.callbacks import BaseCallbackHandler, CallbackManager
from langchain.schema import AgentAction

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(root)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.llm.LLMConfig import get_llm_configs
from src.llm.LLMAgentBuilder import LLMAgentBuilder
from src.llm.PromptManager import SystemPromptManager
from src.rag.ParentDocumentRetriever import VectorDBManager


# ===== é…ç½® =====
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Test"

vectorManager = VectorDBManager()


class CustomHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºå·¥å…·è°ƒç”¨å‰çš„äººå·¥ç¡®è®¤"""

    def on_agent_action(self, action: AgentAction, **kwargs: Any, ) -> None:
        # print(f"\nğŸ§  Agent è®¡åˆ’è°ƒç”¨å·¥å…·: {action.tool}")
        # print(f"ğŸ“¦ å·¥å…·è¾“å…¥: {action.tool_input}")

        # choice = input("â“æ˜¯å¦ç»§ç»­è°ƒç”¨å·¥å…·ï¼Ÿ(y/n): ").strip().lower()
        # if choice != "y":
        #     print("â›” ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨")
        #     # è¿”å›ä¸€ä¸ªç©ºç»“æœï¼Œè®©Agentç»§ç»­æ‰§è¡Œ
        #     raise "ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨è‡ªèº«çŸ¥è¯†å›ç­”"
        pass


# ===== æ¨¡å‹å®šä¹‰ =====
class SearchInput(BaseModel):
    """æœç´¢å·¥å…·çš„è¾“å…¥éªŒè¯æ¨¡å‹"""
    query: str = Field(description="æŸ¥è¯¢çš„å…³é”®è¯æˆ–å†…å®¹")


class RAGInput(BaseModel):
    """çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·çš„è¾“å…¥éªŒè¯æ¨¡å‹"""
    query: str = Field(description="éœ€è¦åœ¨çŸ¥è¯†åº“ä¸­æŸ¥è¯¢çš„é—®é¢˜")


# ===== å·¥å…·å‡½æ•° =====
def _handle_error(error: ToolException) -> str:
    """ç»Ÿä¸€çš„å·¥å…·é”™è¯¯å¤„ç†å‡½æ•°"""
    return f"å·¥å…·æ‰§è¡ŒæœŸé—´å‘ç”Ÿé”™è¯¯ï¼š{str(error)}"


async def search_tool(query: str) -> str:
    """æœç´¢å¼•æ“å·¥å…·"""
    try:
        search = TavilySearchResults(max_results=3)
        results = await search.ainvoke(query)

        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        formatted_results = []
        for i, result in enumerate(results, 1):
            formatted_results.append(
                f"ç»“æœ{i}:\n"
                f"æ ‡é¢˜: {result.get('title', 'æ— æ ‡é¢˜')}\n"
                f"å†…å®¹: {result.get('content', 'æ— å†…å®¹')}\n"
                f"é“¾æ¥: {result.get('url', 'æ— é“¾æ¥')}\n"
            )

        return "æœç´¢ç»“æœ:\n" + "\n".join(formatted_results)

    except Exception as e:
        return f"æœç´¢å‡ºé”™: {str(e)}"


async def interactive_search_tool(query: str) -> str:
    """æœç´¢å¼•æ“å·¥å…·çš„äº¤äº’å¼åŒ…è£…å‡½æ•°"""
    print(f"\nğŸ§  Agent è®¡åˆ’è°ƒç”¨å·¥å…·ï¼šsearch_engine")
    print(f"ğŸ“¦ å·¥å…·è¾“å…¥ï¼š{query}")

    choice = input("â“æ˜¯å¦ç»§ç»­è°ƒç”¨å·¥å…·ï¼Ÿ(y/n): ").strip().lower()
    if choice != "y":
        print("ğŸš« ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç©ºç»“æœ\n")
        return "ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨ï¼Œæœªå®é™…æ‰§è¡Œï¼Œä»…ä½¿ç”¨è‡ªèº«çŸ¥è¯†è¿›è¡Œå›ç­”\n"

    # ç»§ç»­æ‰§è¡ŒåŸå§‹å·¥å…·é€»è¾‘
    return await search_tool(query)


async def rag_tool(query: str) -> str:
    """çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·"""
    try:
        search = await vectorManager.get_retriever(
            "ParentDocumentRetrieverDB",
            3, 0.6, 0.9,
            use_ensemble=True
        )
        docs = await search.ainvoke(query)

        if not docs:
            return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        results = []
        for i, doc in enumerate(docs, 1):
            results.append(
                f"ç»“æœ{i}:\n"
                f"å†…å®¹: {doc.page_content}\n"
                f"æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\n"
                f"æ£€ç´¢å™¨: {doc.metadata.get('retriever', 'vector')}\n"
            )

        return "çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ:\n" + "\n".join(results)

    except Exception as e:
        return f"çŸ¥è¯†åº“æŸ¥è¯¢å‡ºé”™: {str(e)}"


async def interactive_rag_tool(query: str) -> str:
    """çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·çš„äº¤äº’å¼åŒ…è£…å‡½æ•°"""
    print(f"\nğŸ§  Agent è®¡åˆ’è°ƒç”¨å·¥å…·ï¼šknowledge_query")
    print(f"ğŸ“¦ å·¥å…·è¾“å…¥ï¼š{query}")

    choice = input("â“æ˜¯å¦ç»§ç»­è°ƒç”¨å·¥å…·ï¼Ÿ(y/n): ").strip().lower()
    if choice != "y":
        print("ğŸš« ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç©ºç»“æœ\n")
        return "ç”¨æˆ·å–æ¶ˆäº†å·¥å…·è°ƒç”¨ï¼Œæœªå®é™…æ‰§è¡Œï¼Œä»…ä½¿ç”¨è‡ªèº«çŸ¥è¯†è¿›è¡Œå›ç­”\n"

    # ç»§ç»­æ‰§è¡ŒåŸå§‹å·¥å…·é€»è¾‘
    return await rag_tool(query)


def get_agent_history(user_id: str, session_id: str) -> RedisChatMessageHistory:
    """è·å–æˆ–åˆ›å»ºAgentä¼šè¯å†å²"""
    history = RedisChatMessageHistory(session_id=user_id + "-" + session_id, url=vectorManager.redis_url)
    messages = history.messages

    save_messages = trim_messages(
        messages,
        strategy="last",
        token_counter=len,
        max_tokens=20,
        start_on="human",
        end_on=("ai", "tool"),
        include_system=True,
    )

    history.clear()
    for message in save_messages:
        history.add_message(message)

    return history


# ===== å·¥å…·å®šä¹‰ =====
def create_tools() -> List[StructuredTool]:
    """åˆ›å»ºå¹¶è¿”å›å·¥å…·åˆ—è¡¨"""
    return [
        StructuredTool.from_function(
            name="search_engine",
            func=interactive_search_tool,
            description="ç”¨äºåœ¨ç½‘é¡µä¸­æœç´¢è·å–å®æ—¶ä¿¡æ¯ï¼Œè¾“å…¥åº”ä¸ºå­—ç¬¦ä¸²å½¢å¼çš„é—®é¢˜æˆ–å…³é”®å­—",
            args_schema=SearchInput,
            handle_tool_error=_handle_error
        ),
        StructuredTool.from_function(
            name="knowledge_query",
            # func=interactive_rag_tool,
            coroutine=interactive_rag_tool,
            description="ç”¨äºåœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æŸ¥è¯¢ä¿¡æ¯ï¼Œé€‚åˆæŸ¥è¯¢ä¸“ä¸šé¢†åŸŸçŸ¥è¯†",
            args_schema=RAGInput,
            handle_tool_error=_handle_error
        )
    ]


# ===== Agent é…ç½® =====
def setup_agent():
    """è®¾ç½®å¹¶è¿”å›Agent"""
    agent_config = get_llm_configs(
        system_prompt=SystemPromptManager.get_agent_system_prompt(),
        agent=True,
        memory=True
    )

    llm_agent_builder = LLMAgentBuilder(agent_config)

    tools = create_tools()
    llm_agent_builder.add_tools(tools)

    # åˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰å›è°ƒçš„Agentæ‰§è¡Œå™¨
    agent_executor = llm_agent_builder.create_agent_executor(
        verbose=True,
        callback_manager=CallbackManager([CustomHandler()])
    )

    agent_with_history = RunnableWithMessageHistory(
        agent_executor,
        get_agent_history,
        input_messages_key="question",
        history_messages_key="history",
        history_factory_config=[
            ConfigurableFieldSpec(
                id="user_id",
                annotation=str,
                name="User ID",
                description="ç”¨æˆ·å”¯ä¸€æ ‡è¯†",
                default="",
                is_shared=True
            ),
            ConfigurableFieldSpec(
                id="session_id",
                annotation=str,
                name="Session ID",
                description="ä¼šè¯å”¯ä¸€æ ‡è¯†",
                default="",
                is_shared=True
            )
        ]
    )

    return agent_with_history, llm_agent_builder


# ===== èŠå¤©ä¼šè¯ =====
async def async_stream_chat_session():
    """å¼‚æ­¥æµå¼èŠå¤©ä¼šè¯"""
    print("æ¬¢è¿ä½¿ç”¨AgentèŠå¤©åŠ©æ‰‹ï¼ˆå¼‚æ­¥æµå¼ç‰ˆæœ¬ï¼‰ï¼Œè¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")

    user_id = "zby"
    session_id = "session_2"

    agent_with_history, llm_agent_builder = setup_agent()

    while True:
        user_input = input("\nç”¨æˆ·: ")
        if user_input.lower() in ['é€€å‡º', 'exit', 'quit']:
            print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break

        print("\nAIåŠ©æ‰‹: ", end="", flush=True)

        tools_desc = llm_agent_builder.get_tools_description()
        response = await agent_with_history.ainvoke(
            {"tools": tools_desc, "question": user_input},
            config={"configurable": {"user_id": user_id, "session_id": session_id}}
        )
        print(response['output'])


# ===== ä¸»å…¥å£ =====
if __name__ == "__main__":
    asyncio.run(async_stream_chat_session())
